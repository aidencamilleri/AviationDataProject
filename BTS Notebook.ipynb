{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3cf834",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dc074",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "\n",
    "Data from the Bureau of Transpotation Statistics with a Python script. It was downloaded in monthy chunks from Oct. 1987 - Mar. 2023. In total, the uncompressed files are ~94GB.\n",
    "\n",
    "Copy of script in cell below and published on my GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbcbb1",
   "metadata": {},
   "source": [
    "```\n",
    "import requests\n",
    "import certifi\n",
    "\n",
    "baseURL = 'https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_'\n",
    "\n",
    "for i in range(1987, 2023): #grab years from 1987-2022\n",
    "    for j in range(1, 13): #grab months from Jan.-Dec.\n",
    "        specificURL = baseURL + str(i) + '_' + str(j) + \".zip\" #add year and month to make full URL\n",
    "        response = requests.get(specificURL, stream=True) #get file from specified web address\n",
    "        filename = \"BTS_\" + str(j) + '_' + str(i) + \".zip\" #make filename from year and month\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content) #write it to a file\n",
    "```\n",
    "\n",
    "Note: Modification of certifi install is required to have valid SSL certificates for requesting the download from TranStats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df8373",
   "metadata": {},
   "source": [
    "## Data Ingest Trial 1\n",
    "\n",
    "The initial attempt was to load all the data into Pandas dataframes and concatenate them together. I knew it probably wouldn't work (especially b/c Pandas has an upper limit of 100GB per dataframe and I was too close to that). Result was computer ran out of memory and swap and the Python kernel crashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97835d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de9cec",
   "metadata": {},
   "source": [
    "```\n",
    "#This code block iterates through all filepaths to the csv files,\n",
    "# creates a dataframe from that csv file,\n",
    "# and appends the dataframe to the list of dataframes\n",
    "dfList = list()\n",
    "\n",
    "#Latin-1 encoding used because there was an error with default (UTF-8) encoding\n",
    "\n",
    "for month in range(10,13):\n",
    "    path = '/Users/aidencamilleri/Library/CloudStorage/OneDrive-CollegeofCharleston/Personal Projects/Code Projects/BTSDownload/Unzipped/1987/BTS_' + str(month) + '_1987/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_1987_' + str(month) + '.csv'\n",
    "    dfList.append(pd.read_csv(path, encoding = 'latin-1'))\n",
    "    \n",
    "for year in range(1988, 2023):\n",
    "    for month in range(1, 13):\n",
    "        path = '/Users/aidencamilleri/Library/CloudStorage/OneDrive-CollegeofCharleston/Personal Projects/Code Projects/BTSDownload/Unzipped/' + str(year) + '/BTS_' + str(month) + '_' + str(year) + '/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_' + str(year) + '_' + str(month) + '.csv'\n",
    "        dfList.append(pd.read_csv(path, encoding = 'latin-1'))\n",
    "        \n",
    "for month in range(1,4):\n",
    "    path = '/Users/aidencamilleri/Library/CloudStorage/OneDrive-CollegeofCharleston/Personal Projects/Code Projects/BTSDownload/Unzipped/2023/BTS_' + str(month) + '_2023/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_' + str(month) + '.csv'\n",
    "    dfList.append(pd.read_csv(path, encoding = 'latin-1'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0c530",
   "metadata": {},
   "source": [
    "```\n",
    "megaDF = pd.concat(dfList)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91779a",
   "metadata": {},
   "source": [
    "## Data Ingest Trial 2\n",
    "\n",
    "Now I am attempting to import the data into a local Microsoft SQL Server. As I am running this project on a personal MacBook, the MSSQL Server is being hosted in a Docker container. I am having issues importing the individual CSV files into the MSSQL Server because of formatting quirks of the CSV files from the BTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
